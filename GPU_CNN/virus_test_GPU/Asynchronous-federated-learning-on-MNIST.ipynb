{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Asynchronous federated learning on MNIST\n",
    "\n",
    "This notebook will go through the steps to run a federated learning via websocket workers in an asynchronous way using [TrainConfig](https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/advanced/Federated%20Learning%20with%20TrainConfig/Introduction%20to%20TrainConfig.ipynb). We will use federated averaging to join the remotely trained models.\n",
    "\n",
    "Authors:\n",
    "- Silvia - GitHub [@midokura-silvia](https://github.com/midokura-silvia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning setup\n",
    "\n",
    "For a Federated Learning setup with TrainConfig we need different participants:\n",
    "\n",
    "* _Workers_: own datasets.\n",
    "\n",
    "* _Coordinator_: an entity that knows the workers and the dataset name that lives in each worker. \n",
    "\n",
    "* _Evaluator_: holds the testing data and tracks model performance \n",
    "\n",
    "Each worker is represented by two parts, a proxy local to the scheduler (websocket client worker) and the remote instance that holds the data and performs the computations. The remote part is called a websocket server worker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: Start the websocket workers\n",
    "So first, we need to create the remote workers. For this, you need to run in a terminal (not possible from the notebook):\n",
    "\n",
    "```bash\n",
    "python start_websocket_servers.py\n",
    "```\n",
    "\n",
    "#### What's going on?\n",
    "\n",
    "The script will instantiate three workers, Alice, Bob and Charlie and prepare their local data. \n",
    "Each worker is set up to have a subset of the MNIST training dataset. \n",
    "Alice holds all images corresponding to the digits 0-3, \n",
    "Bob holds all images corresponding to the digits 4-6 and \n",
    "Charlie holds all images corresponding to the digits 7-9. \n",
    "\n",
    "| Worker      | Digits in local dataset | Number of samples |\n",
    "| ----------- | ----------------------- | ----------------- |\n",
    "| Alice       | 0-3                     | 24754             |\n",
    "| Bob         | 4-6                     | 17181             |\n",
    "| Charlie     | 7-9                     | 18065             |\n",
    "\n",
    "\n",
    "The evaluator will be called Testing and holds the entire MNIST testing dataset.\n",
    "\n",
    "| Evaluator   | Digits in local dataset | Number of samples |\n",
    "| ----------- | ----------------------- | ----------------- |\n",
    "| Testing     | 0-9                     | 10000             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following to see the code of the function that starts a worker\n",
    "# import run_websocket_server\n",
    "\n",
    "# print(inspect.getsource(run_websocket_server.start_websocket_server_worker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing let's first need to import dependencies, setup needed arguments and configure logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import sys\n",
    "import asyncio\n",
    "\n",
    "import syft as sy\n",
    "from syft.workers.websocket_client import WebsocketClientWorker\n",
    "from syft.frameworks.torch.fl import utils\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "import run_websocket_client as rwc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hook torch\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "Namespace(batch_size=512, cuda=False, federate_after_n_batches=10, lr=1, save_model=False, seed=1, test_batch_size=128, training_rounds=1000, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# Arguments\n",
    "args = rwc.define_and_get_arguments(args=[])\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(torch.cuda.is_available())\n",
    "torch.manual_seed(args.seed)\n",
    "print(use_cuda)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"run_websocket_client\")\n",
    "\n",
    "if not len(logger.handlers):\n",
    "    FORMAT = \"%(asctime)s - %(message)s\"\n",
    "    DATE_FMT = \"%H:%M:%S\"\n",
    "    formatter = logging.Formatter(FORMAT, DATE_FMT)\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.propagate = False\n",
    "LOG_LEVEL = logging.DEBUG\n",
    "logger.setLevel(LOG_LEVEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's instantiate the websocket client workers, our local proxies to the remote workers.\n",
    "Note that **this step will fail, if the websocket server workers are not running**.\n",
    "\n",
    "The workers Alice, Bob and Charlie will perform the training, wheras the testing worker hosts the test data and performs the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kwargs_websocket = {\"host\": \"106.12.19.48\", \"hook\": hook, \"verbose\": args.verbose}\n",
    "#alice = WebsocketClientWorker(id=\"alice\", port=28032, **kwargs_websocket)\n",
    "\n",
    "kwargs_websocket = {\"host\": \"106.12.19.48\", \"hook\": hook, \"verbose\": args.verbose}\n",
    "testing = WebsocketClientWorker(id=\"testing\", port=28007, **kwargs_websocket)\n",
    "\n",
    "kwargs_websocket = {\"host\": \"106.12.19.48\", \"hook\": hook, \"verbose\": args.verbose}\n",
    "bob = WebsocketClientWorker(id=\"bob\", port=28048 , **kwargs_websocket)\n",
    "#charlie = WebsocketClientWorker(id=\"charlie\", port=8779, **kwargs_websocket)\n",
    "\n",
    "worker_instances = [ bob]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Let's instantiate the machine learning model. It is a small neural network with 2 convolutional and two fully connected layers. \n",
    "It uses ReLU activations and max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(inspect.getsource(rwc.Net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 50, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(50, 40, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(40, 30, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu): ReLU()\n",
      "  (fc1): Linear(in_features=120, out_features=120, bias=True)\n",
      "  (fc3): Linear(in_features=120, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = rwc.Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the model serializable\n",
    "\n",
    "In order to send the model to the workers we need the model to be serializable, for this we use [`jit`](https://pytorch.org/docs/stable/jit.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(model, torch.zeros([1,1,22,22], dtype=torch.float).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start the training\n",
    "\n",
    "Now we are ready to start the federated training. We will perform training over a given number of batches separately on each worker and then calculate the federated average of the resulting model.\n",
    "\n",
    "Every 10th training round we will evaluate the performance of the models returned by the workers and of the model obtained by federated averaging. \n",
    "\n",
    "The performance will be given both as the accuracy (ratio of correct predictions) and as the histograms of predicted digits. This is of interest, as each worker only owns a subset of the digits. Therefore, in the beginning each worker will only predict their numbers and only know about the other numbers via the federated averaging process.\n",
    "\n",
    "The training is done in an asynchronous manner. This means that the scheduler just tell the workers to train and does not block to wait for the result of the training before talking to the next worker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of the training are given in the arguments. \n",
    "Each worker will train on a given number of batches, given by the value of federate_after_n_batches.\n",
    "The training batch size and learning rate are also configured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federate_after_n_batches: 10\n",
      "Batch size: 512\n",
      "Initial learning rate: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Federate_after_n_batches: \" + str(args.federate_after_n_batches))\n",
    "print(\"Batch size: \" + str(args.batch_size))\n",
    "print(\"Initial learning rate: \" + str(args.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:15:26 - Training round 1/1000\n",
      "16:15:28 - Evaluating models\n",
      "16:15:29 - Model update bob: Average loss: 0.0125, Accuracy: 551/1598 (34.48%)\n",
      "16:15:29 - Model update bob: Average loss: 0.0125\n",
      "16:15:29 - Federated model: Average loss: 0.0125, Accuracy: 551/1598 (34.48%)\n",
      "16:15:29 - Federated model: Average loss: 0.0125\n",
      "16:15:29 - Training round 2/1000\n",
      "16:15:31 - Training round 3/1000\n",
      "16:15:32 - Training round 4/1000\n",
      "16:15:34 - Training round 5/1000\n",
      "16:15:35 - Training round 6/1000\n",
      "16:15:37 - Training round 7/1000\n",
      "16:15:38 - Training round 8/1000\n",
      "16:15:40 - Training round 9/1000\n",
      "16:15:41 - Training round 10/1000\n",
      "16:15:42 - Training round 11/1000\n",
      "16:15:44 - Evaluating models\n",
      "16:15:44 - Model update bob: Average loss: 0.0118, Accuracy: 570/1598 (35.67%)\n",
      "16:15:44 - Model update bob: Average loss: 0.0118\n",
      "16:15:45 - Federated model: Average loss: 0.0118, Accuracy: 570/1598 (35.67%)\n",
      "16:15:45 - Federated model: Average loss: 0.0118\n",
      "16:15:45 - Training round 12/1000\n",
      "16:15:46 - Training round 13/1000\n",
      "16:15:48 - Training round 14/1000\n",
      "16:15:49 - Training round 15/1000\n",
      "16:15:51 - Training round 16/1000\n",
      "16:15:52 - Training round 17/1000\n",
      "16:15:55 - Training round 18/1000\n",
      "16:15:57 - Training round 19/1000\n",
      "16:15:58 - Training round 20/1000\n",
      "16:16:00 - Training round 21/1000\n",
      "16:16:01 - Evaluating models\n",
      "16:16:02 - Model update bob: Average loss: 0.0126, Accuracy: 667/1598 (41.74%)\n",
      "16:16:02 - Model update bob: Average loss: 0.0126\n",
      "16:16:02 - Federated model: Average loss: 0.0126, Accuracy: 667/1598 (41.74%)\n",
      "16:16:02 - Federated model: Average loss: 0.0126\n",
      "16:16:02 - Training round 22/1000\n",
      "16:16:04 - Training round 23/1000\n",
      "16:16:05 - Training round 24/1000\n",
      "16:16:07 - Training round 25/1000\n",
      "16:16:08 - Training round 26/1000\n",
      "16:16:10 - Training round 27/1000\n",
      "16:16:11 - Training round 28/1000\n",
      "16:16:13 - Training round 29/1000\n",
      "16:16:14 - Training round 30/1000\n",
      "16:16:17 - Training round 31/1000\n",
      "16:16:18 - Evaluating models\n",
      "16:16:19 - Model update bob: Average loss: 0.0088, Accuracy: 981/1598 (61.39%)\n",
      "16:16:19 - Model update bob: Average loss: 0.0088\n",
      "16:16:19 - Federated model: Average loss: 0.0088, Accuracy: 981/1598 (61.39%)\n",
      "16:16:19 - Federated model: Average loss: 0.0088\n",
      "16:16:19 - Training round 32/1000\n",
      "16:16:20 - Training round 33/1000\n",
      "16:16:22 - Training round 34/1000\n",
      "16:16:24 - Training round 35/1000\n",
      "16:16:25 - Training round 36/1000\n",
      "16:16:27 - Training round 37/1000\n",
      "16:16:28 - Training round 38/1000\n",
      "16:16:30 - Training round 39/1000\n",
      "16:16:32 - Training round 40/1000\n",
      "16:16:34 - Training round 41/1000\n",
      "16:16:35 - Evaluating models\n",
      "16:16:36 - Model update bob: Average loss: 0.0109, Accuracy: 972/1598 (60.83%)\n",
      "16:16:36 - Model update bob: Average loss: 0.0109\n",
      "16:16:36 - Federated model: Average loss: 0.0109, Accuracy: 972/1598 (60.83%)\n",
      "16:16:36 - Federated model: Average loss: 0.0109\n",
      "16:16:36 - Training round 42/1000\n",
      "16:16:38 - Training round 43/1000\n",
      "16:16:40 - Training round 44/1000\n",
      "16:16:41 - Training round 45/1000\n",
      "16:16:43 - Training round 46/1000\n",
      "16:16:45 - Training round 47/1000\n",
      "16:16:46 - Training round 48/1000\n",
      "16:16:48 - Training round 49/1000\n",
      "16:16:50 - Training round 50/1000\n",
      "16:16:52 - Training round 51/1000\n",
      "16:16:54 - Evaluating models\n",
      "16:16:55 - Model update bob: Average loss: 0.0113, Accuracy: 863/1598 (54.01%)\n",
      "16:16:55 - Model update bob: Average loss: 0.0113\n",
      "16:16:55 - Federated model: Average loss: 0.0113, Accuracy: 863/1598 (54.01%)\n",
      "16:16:55 - Federated model: Average loss: 0.0113\n",
      "16:16:55 - Training round 52/1000\n",
      "16:16:57 - Training round 53/1000\n",
      "16:16:58 - Training round 54/1000\n",
      "16:17:00 - Training round 55/1000\n",
      "16:17:02 - Training round 56/1000\n",
      "16:17:03 - Training round 57/1000\n",
      "16:17:05 - Training round 58/1000\n",
      "16:17:07 - Training round 59/1000\n",
      "16:17:09 - Training round 60/1000\n",
      "16:17:10 - Training round 61/1000\n",
      "16:17:12 - Evaluating models\n",
      "16:17:13 - Model update bob: Average loss: 0.0127, Accuracy: 790/1598 (49.44%)\n",
      "16:17:13 - Model update bob: Average loss: 0.0127\n",
      "16:17:13 - Federated model: Average loss: 0.0127, Accuracy: 790/1598 (49.44%)\n",
      "16:17:13 - Federated model: Average loss: 0.0127\n",
      "16:17:13 - Training round 62/1000\n",
      "16:17:15 - Training round 63/1000\n",
      "16:17:17 - Training round 64/1000\n",
      "16:17:18 - Training round 65/1000\n",
      "16:17:20 - Training round 66/1000\n",
      "16:17:22 - Training round 67/1000\n",
      "16:17:24 - Training round 68/1000\n",
      "16:17:26 - Training round 69/1000\n",
      "16:17:27 - Training round 70/1000\n",
      "16:17:29 - Training round 71/1000\n",
      "16:17:31 - Evaluating models\n",
      "16:17:31 - Model update bob: Average loss: 0.0139, Accuracy: 721/1598 (45.12%)\n",
      "16:17:31 - Model update bob: Average loss: 0.0139\n",
      "16:17:32 - Federated model: Average loss: 0.0139, Accuracy: 721/1598 (45.12%)\n",
      "16:17:32 - Federated model: Average loss: 0.0139\n",
      "16:17:32 - Training round 72/1000\n",
      "16:17:34 - Training round 73/1000\n",
      "16:17:36 - Training round 74/1000\n",
      "16:17:37 - Training round 75/1000\n",
      "16:17:39 - Training round 76/1000\n",
      "16:17:41 - Training round 77/1000\n",
      "16:17:43 - Training round 78/1000\n",
      "16:17:44 - Training round 79/1000\n",
      "16:17:46 - Training round 80/1000\n",
      "16:17:48 - Training round 81/1000\n",
      "16:17:50 - Evaluating models\n",
      "16:17:50 - Model update bob: Average loss: 0.0136, Accuracy: 803/1598 (50.25%)\n",
      "16:17:50 - Model update bob: Average loss: 0.0136\n",
      "16:17:51 - Federated model: Average loss: 0.0136, Accuracy: 803/1598 (50.25%)\n",
      "16:17:51 - Federated model: Average loss: 0.0136\n",
      "16:17:51 - Training round 82/1000\n",
      "16:17:52 - Training round 83/1000\n",
      "16:17:55 - Training round 84/1000\n",
      "16:17:57 - Training round 85/1000\n",
      "16:17:58 - Training round 86/1000\n",
      "16:18:00 - Training round 87/1000\n",
      "16:18:02 - Training round 88/1000\n",
      "16:18:04 - Training round 89/1000\n",
      "16:18:06 - Training round 90/1000\n",
      "16:18:08 - Training round 91/1000\n",
      "16:18:10 - Evaluating models\n",
      "16:18:10 - Model update bob: Average loss: 0.0141, Accuracy: 730/1598 (45.68%)\n",
      "16:18:10 - Model update bob: Average loss: 0.0141\n",
      "16:18:10 - Federated model: Average loss: 0.0141, Accuracy: 730/1598 (45.68%)\n",
      "16:18:10 - Federated model: Average loss: 0.0141\n",
      "16:18:10 - Training round 92/1000\n",
      "16:18:12 - Training round 93/1000\n",
      "16:18:14 - Training round 94/1000\n",
      "16:18:16 - Training round 95/1000\n",
      "16:18:17 - Training round 96/1000\n",
      "16:18:19 - Training round 97/1000\n",
      "16:18:21 - Training round 98/1000\n",
      "16:18:22 - Training round 99/1000\n",
      "16:18:24 - Training round 100/1000\n",
      "16:18:26 - Training round 101/1000\n",
      "16:18:27 - Evaluating models\n",
      "16:18:28 - Model update bob: Average loss: 0.0126, Accuracy: 865/1598 (54.13%)\n",
      "16:18:28 - Model update bob: Average loss: 0.0126\n",
      "16:18:28 - Federated model: Average loss: 0.0126, Accuracy: 865/1598 (54.13%)\n",
      "16:18:28 - Federated model: Average loss: 0.0126\n",
      "16:18:28 - Training round 102/1000\n",
      "16:18:30 - Training round 103/1000\n",
      "16:18:32 - Training round 104/1000\n",
      "16:18:34 - Training round 105/1000\n",
      "16:18:35 - Training round 106/1000\n",
      "16:18:37 - Training round 107/1000\n",
      "16:18:38 - Training round 108/1000\n",
      "16:18:40 - Training round 109/1000\n",
      "16:18:42 - Training round 110/1000\n",
      "16:18:43 - Training round 111/1000\n",
      "16:18:45 - Evaluating models\n",
      "16:18:45 - Model update bob: Average loss: 0.0142, Accuracy: 832/1598 (52.07%)\n",
      "16:18:45 - Model update bob: Average loss: 0.0142\n",
      "16:18:46 - Federated model: Average loss: 0.0142, Accuracy: 832/1598 (52.07%)\n",
      "16:18:46 - Federated model: Average loss: 0.0142\n",
      "16:18:46 - Training round 112/1000\n",
      "16:18:47 - Training round 113/1000\n",
      "16:18:49 - Training round 114/1000\n",
      "16:18:51 - Training round 115/1000\n",
      "16:18:52 - Training round 116/1000\n",
      "16:18:54 - Training round 117/1000\n",
      "16:18:57 - Training round 118/1000\n",
      "16:18:59 - Training round 119/1000\n",
      "16:19:00 - Training round 120/1000\n",
      "16:19:02 - Training round 121/1000\n",
      "16:19:04 - Evaluating models\n",
      "16:19:04 - Model update bob: Average loss: 0.0139, Accuracy: 853/1598 (53.38%)\n",
      "16:19:04 - Model update bob: Average loss: 0.0139\n",
      "16:19:05 - Federated model: Average loss: 0.0139, Accuracy: 853/1598 (53.38%)\n",
      "16:19:05 - Federated model: Average loss: 0.0139\n",
      "16:19:05 - Training round 122/1000\n",
      "16:19:06 - Training round 123/1000\n",
      "16:19:08 - Training round 124/1000\n",
      "16:19:10 - Training round 125/1000\n",
      "16:19:12 - Training round 126/1000\n",
      "16:19:13 - Training round 127/1000\n",
      "16:19:15 - Training round 128/1000\n",
      "16:19:17 - Training round 129/1000\n",
      "16:19:18 - Training round 130/1000\n",
      "16:19:20 - Training round 131/1000\n",
      "16:19:22 - Evaluating models\n",
      "16:19:22 - Model update bob: Average loss: 0.0143, Accuracy: 818/1598 (51.19%)\n",
      "16:19:22 - Model update bob: Average loss: 0.0143\n",
      "16:19:23 - Federated model: Average loss: 0.0143, Accuracy: 818/1598 (51.19%)\n",
      "16:19:23 - Federated model: Average loss: 0.0143\n",
      "16:19:23 - Training round 132/1000\n",
      "16:19:25 - Training round 133/1000\n",
      "16:19:26 - Training round 134/1000\n",
      "16:19:28 - Training round 135/1000\n",
      "16:19:30 - Training round 136/1000\n",
      "16:19:31 - Training round 137/1000\n",
      "16:19:33 - Training round 138/1000\n",
      "16:19:35 - Training round 139/1000\n",
      "16:19:36 - Training round 140/1000\n",
      "16:19:38 - Training round 141/1000\n",
      "16:19:40 - Evaluating models\n",
      "16:19:40 - Model update bob: Average loss: 0.0155, Accuracy: 797/1598 (49.87%)\n",
      "16:19:40 - Model update bob: Average loss: 0.0155\n",
      "16:19:41 - Federated model: Average loss: 0.0155, Accuracy: 797/1598 (49.87%)\n",
      "16:19:41 - Federated model: Average loss: 0.0155\n",
      "16:19:41 - Training round 142/1000\n",
      "16:19:42 - Training round 143/1000\n",
      "16:19:44 - Training round 144/1000\n",
      "16:19:46 - Training round 145/1000\n",
      "16:19:47 - Training round 146/1000\n",
      "16:19:49 - Training round 147/1000\n",
      "16:19:51 - Training round 148/1000\n",
      "16:19:52 - Training round 149/1000\n",
      "16:19:54 - Training round 150/1000\n",
      "16:19:56 - Training round 151/1000\n",
      "16:19:57 - Evaluating models\n",
      "16:19:58 - Model update bob: Average loss: 0.0143, Accuracy: 864/1598 (54.07%)\n",
      "16:19:58 - Model update bob: Average loss: 0.0143\n",
      "16:19:58 - Federated model: Average loss: 0.0143, Accuracy: 864/1598 (54.07%)\n",
      "16:19:58 - Federated model: Average loss: 0.0143\n",
      "16:19:58 - Training round 152/1000\n",
      "16:20:00 - Training round 153/1000\n",
      "16:20:02 - Training round 154/1000\n",
      "16:20:04 - Training round 155/1000\n",
      "16:20:05 - Training round 156/1000\n",
      "16:20:07 - Training round 157/1000\n",
      "16:20:09 - Training round 158/1000\n",
      "16:20:10 - Training round 159/1000\n",
      "16:20:12 - Training round 160/1000\n",
      "16:20:14 - Training round 161/1000\n",
      "16:20:15 - Evaluating models\n",
      "16:20:16 - Model update bob: Average loss: 0.0142, Accuracy: 892/1598 (55.82%)\n",
      "16:20:16 - Model update bob: Average loss: 0.0142\n",
      "16:20:16 - Federated model: Average loss: 0.0142, Accuracy: 892/1598 (55.82%)\n",
      "16:20:16 - Federated model: Average loss: 0.0142\n",
      "16:20:16 - Training round 162/1000\n",
      "16:20:18 - Training round 163/1000\n",
      "16:20:20 - Training round 164/1000\n",
      "16:20:22 - Training round 165/1000\n",
      "16:20:23 - Training round 166/1000\n",
      "16:20:25 - Training round 167/1000\n",
      "16:20:27 - Training round 168/1000\n",
      "16:20:28 - Training round 169/1000\n",
      "16:20:30 - Training round 170/1000\n",
      "16:20:32 - Training round 171/1000\n",
      "16:20:34 - Evaluating models\n",
      "16:20:34 - Model update bob: Average loss: 0.0153, Accuracy: 853/1598 (53.38%)\n",
      "16:20:34 - Model update bob: Average loss: 0.0153\n",
      "16:20:34 - Federated model: Average loss: 0.0153, Accuracy: 853/1598 (53.38%)\n",
      "16:20:34 - Federated model: Average loss: 0.0153\n",
      "16:20:34 - Training round 172/1000\n",
      "16:20:36 - Training round 173/1000\n",
      "16:20:38 - Training round 174/1000\n",
      "16:20:40 - Training round 175/1000\n",
      "16:20:41 - Training round 176/1000\n",
      "16:20:43 - Training round 177/1000\n",
      "16:20:45 - Training round 178/1000\n",
      "16:20:47 - Training round 179/1000\n",
      "16:20:48 - Training round 180/1000\n",
      "16:20:50 - Training round 181/1000\n",
      "16:20:52 - Evaluating models\n",
      "16:20:52 - Model update bob: Average loss: 0.0156, Accuracy: 840/1598 (52.57%)\n",
      "16:20:52 - Model update bob: Average loss: 0.0156\n",
      "16:20:52 - Federated model: Average loss: 0.0156, Accuracy: 840/1598 (52.57%)\n",
      "16:20:52 - Federated model: Average loss: 0.0156\n",
      "16:20:52 - Training round 182/1000\n",
      "16:20:54 - Training round 183/1000\n",
      "16:20:56 - Training round 184/1000\n",
      "16:20:58 - Training round 185/1000\n",
      "16:21:00 - Training round 186/1000\n",
      "16:21:02 - Training round 187/1000\n",
      "16:21:03 - Training round 188/1000\n",
      "16:21:06 - Training round 189/1000\n",
      "16:21:08 - Training round 190/1000\n",
      "16:21:09 - Training round 191/1000\n",
      "16:21:11 - Evaluating models\n",
      "16:21:12 - Model update bob: Average loss: 0.0157, Accuracy: 844/1598 (52.82%)\n",
      "16:21:12 - Model update bob: Average loss: 0.0157\n",
      "16:21:12 - Federated model: Average loss: 0.0157, Accuracy: 844/1598 (52.82%)\n",
      "16:21:12 - Federated model: Average loss: 0.0157\n",
      "16:21:12 - Training round 192/1000\n",
      "16:21:15 - Training round 193/1000\n",
      "16:21:16 - Training round 194/1000\n",
      "16:21:18 - Training round 195/1000\n",
      "16:21:20 - Training round 196/1000\n",
      "16:21:22 - Training round 197/1000\n",
      "16:21:23 - Training round 198/1000\n",
      "16:21:25 - Training round 199/1000\n",
      "16:21:27 - Training round 200/1000\n",
      "16:21:28 - Training round 201/1000\n",
      "16:21:30 - Evaluating models\n",
      "16:21:31 - Model update bob: Average loss: 0.0156, Accuracy: 868/1598 (54.32%)\n",
      "16:21:31 - Model update bob: Average loss: 0.0156\n",
      "16:21:31 - Federated model: Average loss: 0.0156, Accuracy: 868/1598 (54.32%)\n",
      "16:21:31 - Federated model: Average loss: 0.0156\n",
      "16:21:31 - Training round 202/1000\n",
      "16:21:33 - Training round 203/1000\n",
      "16:21:34 - Training round 204/1000\n",
      "16:21:36 - Training round 205/1000\n",
      "16:21:38 - Training round 206/1000\n",
      "16:21:39 - Training round 207/1000\n",
      "16:21:41 - Training round 208/1000\n",
      "16:21:43 - Training round 209/1000\n",
      "16:21:44 - Training round 210/1000\n",
      "16:21:46 - Training round 211/1000\n",
      "16:21:48 - Evaluating models\n",
      "16:21:48 - Model update bob: Average loss: 0.0157, Accuracy: 864/1598 (54.07%)\n",
      "16:21:48 - Model update bob: Average loss: 0.0157\n",
      "16:21:49 - Federated model: Average loss: 0.0157, Accuracy: 864/1598 (54.07%)\n",
      "16:21:49 - Federated model: Average loss: 0.0157\n",
      "16:21:49 - Training round 212/1000\n",
      "16:21:51 - Training round 213/1000\n",
      "16:21:52 - Training round 214/1000\n",
      "16:21:54 - Training round 215/1000\n",
      "16:21:56 - Training round 216/1000\n",
      "16:21:58 - Training round 217/1000\n",
      "16:22:00 - Training round 218/1000\n",
      "16:22:01 - Training round 219/1000\n",
      "16:22:03 - Training round 220/1000\n",
      "16:22:05 - Training round 221/1000\n",
      "16:22:07 - Evaluating models\n",
      "16:22:07 - Model update bob: Average loss: 0.0162, Accuracy: 841/1598 (52.63%)\n",
      "16:22:07 - Model update bob: Average loss: 0.0162\n",
      "16:22:08 - Federated model: Average loss: 0.0162, Accuracy: 841/1598 (52.63%)\n",
      "16:22:08 - Federated model: Average loss: 0.0162\n",
      "16:22:08 - Training round 222/1000\n",
      "16:22:10 - Training round 223/1000\n",
      "16:22:11 - Training round 224/1000\n",
      "16:22:14 - Training round 225/1000\n",
      "16:22:16 - Training round 226/1000\n",
      "16:22:18 - Training round 227/1000\n",
      "16:22:20 - Training round 228/1000\n",
      "16:22:23 - Training round 229/1000\n",
      "16:22:25 - Training round 230/1000\n",
      "16:22:27 - Training round 231/1000\n",
      "16:22:28 - Evaluating models\n",
      "16:22:29 - Model update bob: Average loss: 0.0160, Accuracy: 851/1598 (53.25%)\n",
      "16:22:29 - Model update bob: Average loss: 0.0160\n",
      "16:22:29 - Federated model: Average loss: 0.0160, Accuracy: 851/1598 (53.25%)\n",
      "16:22:29 - Federated model: Average loss: 0.0160\n",
      "16:22:29 - Training round 232/1000\n",
      "16:22:31 - Training round 233/1000\n",
      "16:22:33 - Training round 234/1000\n",
      "16:22:34 - Training round 235/1000\n",
      "16:22:36 - Training round 236/1000\n",
      "16:22:38 - Training round 237/1000\n",
      "16:22:40 - Training round 238/1000\n",
      "16:22:41 - Training round 239/1000\n",
      "16:22:43 - Training round 240/1000\n",
      "16:22:45 - Training round 241/1000\n",
      "16:22:47 - Evaluating models\n",
      "16:22:47 - Model update bob: Average loss: 0.0159, Accuracy: 863/1598 (54.01%)\n",
      "16:22:47 - Model update bob: Average loss: 0.0159\n",
      "16:22:47 - Federated model: Average loss: 0.0159, Accuracy: 863/1598 (54.01%)\n",
      "16:22:47 - Federated model: Average loss: 0.0159\n",
      "16:22:47 - Training round 242/1000\n",
      "16:22:49 - Training round 243/1000\n",
      "16:22:51 - Training round 244/1000\n",
      "16:22:53 - Training round 245/1000\n",
      "16:22:55 - Training round 246/1000\n",
      "16:22:57 - Training round 247/1000\n",
      "16:22:59 - Training round 248/1000\n",
      "16:23:00 - Training round 249/1000\n",
      "16:23:02 - Training round 250/1000\n",
      "16:23:04 - Training round 251/1000\n",
      "16:23:06 - Evaluating models\n",
      "16:23:06 - Model update bob: Average loss: 0.0162, Accuracy: 855/1598 (53.50%)\n",
      "16:23:06 - Model update bob: Average loss: 0.0162\n",
      "16:23:07 - Federated model: Average loss: 0.0162, Accuracy: 855/1598 (53.50%)\n",
      "16:23:07 - Federated model: Average loss: 0.0162\n",
      "16:23:07 - Training round 252/1000\n",
      "16:23:08 - Training round 253/1000\n",
      "16:23:10 - Training round 254/1000\n",
      "16:23:12 - Training round 255/1000\n",
      "16:23:14 - Training round 256/1000\n",
      "16:23:16 - Training round 257/1000\n",
      "16:23:18 - Training round 258/1000\n",
      "16:23:19 - Training round 259/1000\n",
      "16:23:21 - Training round 260/1000\n",
      "16:23:23 - Training round 261/1000\n",
      "16:23:25 - Evaluating models\n",
      "16:23:25 - Model update bob: Average loss: 0.0163, Accuracy: 855/1598 (53.50%)\n",
      "16:23:25 - Model update bob: Average loss: 0.0163\n",
      "16:23:26 - Federated model: Average loss: 0.0163, Accuracy: 855/1598 (53.50%)\n",
      "16:23:26 - Federated model: Average loss: 0.0163\n",
      "16:23:26 - Training round 262/1000\n",
      "16:23:28 - Training round 263/1000\n",
      "16:23:29 - Training round 264/1000\n",
      "16:23:31 - Training round 265/1000\n",
      "16:23:33 - Training round 266/1000\n",
      "16:23:34 - Training round 267/1000\n",
      "16:23:36 - Training round 268/1000\n",
      "16:23:38 - Training round 269/1000\n",
      "16:23:41 - Training round 270/1000\n",
      "16:23:43 - Training round 271/1000\n",
      "16:23:45 - Evaluating models\n",
      "16:23:46 - Model update bob: Average loss: 0.0164, Accuracy: 850/1598 (53.19%)\n",
      "16:23:46 - Model update bob: Average loss: 0.0164\n",
      "16:23:46 - Federated model: Average loss: 0.0164, Accuracy: 850/1598 (53.19%)\n",
      "16:23:46 - Federated model: Average loss: 0.0164\n",
      "16:23:46 - Training round 272/1000\n",
      "16:23:48 - Training round 273/1000\n",
      "16:23:50 - Training round 274/1000\n",
      "16:23:52 - Training round 275/1000\n",
      "16:23:54 - Training round 276/1000\n",
      "16:23:57 - Training round 277/1000\n",
      "16:23:59 - Training round 278/1000\n",
      "16:24:01 - Training round 279/1000\n",
      "16:24:03 - Training round 280/1000\n",
      "16:24:05 - Training round 281/1000\n",
      "16:24:07 - Evaluating models\n",
      "16:24:08 - Model update bob: Average loss: 0.0163, Accuracy: 854/1598 (53.44%)\n",
      "16:24:08 - Model update bob: Average loss: 0.0163\n",
      "16:24:08 - Federated model: Average loss: 0.0163, Accuracy: 854/1598 (53.44%)\n",
      "16:24:08 - Federated model: Average loss: 0.0163\n",
      "16:24:08 - Training round 282/1000\n",
      "16:24:10 - Training round 283/1000\n",
      "16:24:12 - Training round 284/1000\n",
      "16:24:14 - Training round 285/1000\n",
      "16:24:16 - Training round 286/1000\n",
      "16:24:18 - Training round 287/1000\n",
      "16:24:20 - Training round 288/1000\n",
      "16:24:21 - Training round 289/1000\n",
      "16:24:23 - Training round 290/1000\n",
      "16:24:25 - Training round 291/1000\n",
      "16:24:27 - Evaluating models\n",
      "16:24:28 - Model update bob: Average loss: 0.0163, Accuracy: 860/1598 (53.82%)\n",
      "16:24:28 - Model update bob: Average loss: 0.0163\n",
      "16:24:28 - Federated model: Average loss: 0.0163, Accuracy: 860/1598 (53.82%)\n",
      "16:24:28 - Federated model: Average loss: 0.0163\n",
      "16:24:28 - Training round 292/1000\n",
      "16:24:30 - Training round 293/1000\n",
      "16:24:32 - Training round 294/1000\n",
      "16:24:34 - Training round 295/1000\n",
      "16:24:36 - Training round 296/1000\n",
      "16:24:38 - Training round 297/1000\n",
      "16:24:40 - Training round 298/1000\n",
      "16:24:41 - Training round 299/1000\n",
      "16:24:43 - Training round 300/1000\n",
      "16:24:45 - Training round 301/1000\n",
      "16:24:47 - Evaluating models\n",
      "16:24:47 - Model update bob: Average loss: 0.0165, Accuracy: 860/1598 (53.82%)\n",
      "16:24:47 - Model update bob: Average loss: 0.0165\n",
      "16:24:48 - Federated model: Average loss: 0.0165, Accuracy: 860/1598 (53.82%)\n",
      "16:24:48 - Federated model: Average loss: 0.0165\n",
      "16:24:48 - Training round 302/1000\n",
      "16:24:50 - Training round 303/1000\n",
      "16:24:52 - Training round 304/1000\n",
      "16:24:54 - Training round 305/1000\n",
      "16:24:56 - Training round 306/1000\n",
      "16:24:58 - Training round 307/1000\n",
      "16:24:59 - Training round 308/1000\n",
      "16:25:01 - Training round 309/1000\n",
      "16:25:03 - Training round 310/1000\n",
      "16:25:05 - Training round 311/1000\n",
      "16:25:07 - Evaluating models\n",
      "16:25:08 - Model update bob: Average loss: 0.0168, Accuracy: 857/1598 (53.63%)\n",
      "16:25:08 - Model update bob: Average loss: 0.0168\n",
      "16:25:08 - Federated model: Average loss: 0.0168, Accuracy: 857/1598 (53.63%)\n",
      "16:25:08 - Federated model: Average loss: 0.0168\n",
      "16:25:08 - Training round 312/1000\n",
      "16:25:10 - Training round 313/1000\n",
      "16:25:12 - Training round 314/1000\n",
      "16:25:14 - Training round 315/1000\n",
      "16:25:16 - Training round 316/1000\n",
      "16:25:18 - Training round 317/1000\n",
      "16:25:20 - Training round 318/1000\n",
      "16:25:22 - Training round 319/1000\n",
      "16:25:24 - Training round 320/1000\n",
      "16:25:26 - Training round 321/1000\n",
      "16:25:29 - Evaluating models\n",
      "16:25:30 - Model update bob: Average loss: 0.0165, Accuracy: 860/1598 (53.82%)\n",
      "16:25:30 - Model update bob: Average loss: 0.0165\n",
      "16:25:30 - Federated model: Average loss: 0.0165, Accuracy: 860/1598 (53.82%)\n",
      "16:25:30 - Federated model: Average loss: 0.0165\n",
      "16:25:30 - Training round 322/1000\n",
      "16:25:32 - Training round 323/1000\n",
      "16:25:34 - Training round 324/1000\n",
      "16:25:36 - Training round 325/1000\n",
      "16:25:38 - Training round 326/1000\n",
      "16:25:40 - Training round 327/1000\n",
      "16:25:42 - Training round 328/1000\n",
      "16:25:44 - Training round 329/1000\n",
      "16:25:46 - Training round 330/1000\n",
      "16:25:48 - Training round 331/1000\n",
      "16:25:50 - Evaluating models\n",
      "16:25:50 - Model update bob: Average loss: 0.0166, Accuracy: 861/1598 (53.88%)\n",
      "16:25:50 - Model update bob: Average loss: 0.0166\n",
      "16:25:51 - Federated model: Average loss: 0.0166, Accuracy: 861/1598 (53.88%)\n",
      "16:25:51 - Federated model: Average loss: 0.0166\n",
      "16:25:51 - Training round 332/1000\n",
      "16:25:53 - Training round 333/1000\n",
      "16:25:54 - Training round 334/1000\n",
      "16:25:56 - Training round 335/1000\n",
      "16:25:58 - Training round 336/1000\n",
      "16:26:00 - Training round 337/1000\n",
      "16:26:02 - Training round 338/1000\n",
      "16:26:04 - Training round 339/1000\n",
      "16:26:06 - Training round 340/1000\n",
      "16:26:08 - Training round 341/1000\n",
      "16:26:10 - Evaluating models\n",
      "16:26:10 - Model update bob: Average loss: 0.0169, Accuracy: 856/1598 (53.57%)\n",
      "16:26:10 - Model update bob: Average loss: 0.0169\n",
      "16:26:10 - Federated model: Average loss: 0.0169, Accuracy: 856/1598 (53.57%)\n",
      "16:26:10 - Federated model: Average loss: 0.0169\n",
      "16:26:10 - Training round 342/1000\n",
      "16:26:12 - Training round 343/1000\n",
      "16:26:14 - Training round 344/1000\n",
      "16:26:17 - Training round 345/1000\n",
      "16:26:19 - Training round 346/1000\n",
      "16:26:21 - Training round 347/1000\n",
      "16:26:22 - Training round 348/1000\n",
      "16:26:24 - Training round 349/1000\n",
      "16:26:27 - Training round 350/1000\n",
      "16:26:29 - Training round 351/1000\n",
      "16:26:32 - Evaluating models\n",
      "16:26:32 - Model update bob: Average loss: 0.0168, Accuracy: 857/1598 (53.63%)\n",
      "16:26:32 - Model update bob: Average loss: 0.0168\n",
      "16:26:32 - Federated model: Average loss: 0.0168, Accuracy: 857/1598 (53.63%)\n",
      "16:26:32 - Federated model: Average loss: 0.0168\n",
      "16:26:32 - Training round 352/1000\n",
      "16:26:35 - Training round 353/1000\n",
      "16:26:37 - Training round 354/1000\n",
      "16:26:39 - Training round 355/1000\n",
      "16:26:41 - Training round 356/1000\n",
      "16:26:43 - Training round 357/1000\n",
      "16:26:45 - Training round 358/1000\n",
      "16:26:47 - Training round 359/1000\n",
      "16:26:49 - Training round 360/1000\n",
      "16:26:51 - Training round 361/1000\n",
      "16:26:53 - Evaluating models\n",
      "16:26:53 - Model update bob: Average loss: 0.0170, Accuracy: 855/1598 (53.50%)\n",
      "16:26:53 - Model update bob: Average loss: 0.0170\n",
      "16:26:53 - Federated model: Average loss: 0.0170, Accuracy: 855/1598 (53.50%)\n",
      "16:26:53 - Federated model: Average loss: 0.0170\n",
      "16:26:53 - Training round 362/1000\n",
      "16:26:55 - Training round 363/1000\n",
      "16:26:57 - Training round 364/1000\n",
      "16:26:59 - Training round 365/1000\n",
      "16:27:01 - Training round 366/1000\n",
      "16:27:03 - Training round 367/1000\n",
      "16:27:05 - Training round 368/1000\n",
      "16:27:07 - Training round 369/1000\n",
      "16:27:10 - Training round 370/1000\n",
      "16:27:12 - Training round 371/1000\n",
      "16:27:14 - Evaluating models\n",
      "16:27:15 - Model update bob: Average loss: 0.0170, Accuracy: 858/1598 (53.69%)\n",
      "16:27:15 - Model update bob: Average loss: 0.0170\n",
      "16:27:15 - Federated model: Average loss: 0.0170, Accuracy: 858/1598 (53.69%)\n",
      "16:27:15 - Federated model: Average loss: 0.0170\n",
      "16:27:15 - Training round 372/1000\n",
      "16:27:17 - Training round 373/1000\n",
      "16:27:19 - Training round 374/1000\n",
      "16:27:21 - Training round 375/1000\n",
      "16:27:23 - Training round 376/1000\n",
      "16:27:25 - Training round 377/1000\n",
      "16:27:27 - Training round 378/1000\n",
      "16:27:29 - Training round 379/1000\n",
      "16:27:31 - Training round 380/1000\n",
      "16:27:33 - Training round 381/1000\n",
      "16:27:35 - Evaluating models\n",
      "16:27:35 - Model update bob: Average loss: 0.0171, Accuracy: 855/1598 (53.50%)\n",
      "16:27:35 - Model update bob: Average loss: 0.0171\n",
      "16:27:35 - Federated model: Average loss: 0.0171, Accuracy: 855/1598 (53.50%)\n",
      "16:27:35 - Federated model: Average loss: 0.0171\n",
      "16:27:35 - Training round 382/1000\n",
      "16:27:37 - Training round 383/1000\n",
      "16:27:39 - Training round 384/1000\n",
      "16:27:41 - Training round 385/1000\n",
      "16:27:43 - Training round 386/1000\n",
      "16:27:45 - Training round 387/1000\n",
      "16:27:47 - Training round 388/1000\n",
      "16:27:49 - Training round 389/1000\n",
      "16:27:51 - Training round 390/1000\n",
      "16:27:53 - Training round 391/1000\n",
      "16:27:55 - Evaluating models\n",
      "16:27:56 - Model update bob: Average loss: 0.0171, Accuracy: 862/1598 (53.94%)\n",
      "16:27:56 - Model update bob: Average loss: 0.0171\n",
      "16:27:56 - Federated model: Average loss: 0.0171, Accuracy: 862/1598 (53.94%)\n",
      "16:27:56 - Federated model: Average loss: 0.0171\n",
      "16:27:56 - Training round 392/1000\n",
      "16:27:58 - Training round 393/1000\n",
      "16:28:00 - Training round 394/1000\n",
      "16:28:02 - Training round 395/1000\n",
      "16:28:04 - Training round 396/1000\n",
      "16:28:05 - Training round 397/1000\n",
      "16:28:07 - Training round 398/1000\n",
      "16:28:10 - Training round 399/1000\n",
      "16:28:12 - Training round 400/1000\n",
      "16:28:14 - Training round 401/1000\n",
      "16:28:15 - Evaluating models\n",
      "16:28:16 - Model update bob: Average loss: 0.0172, Accuracy: 857/1598 (53.63%)\n",
      "16:28:16 - Model update bob: Average loss: 0.0172\n",
      "16:28:16 - Federated model: Average loss: 0.0172, Accuracy: 857/1598 (53.63%)\n",
      "16:28:16 - Federated model: Average loss: 0.0172\n",
      "16:28:16 - Training round 402/1000\n",
      "16:28:18 - Training round 403/1000\n",
      "16:28:20 - Training round 404/1000\n",
      "16:28:22 - Training round 405/1000\n",
      "16:28:24 - Training round 406/1000\n",
      "16:28:26 - Training round 407/1000\n",
      "16:28:28 - Training round 408/1000\n",
      "16:28:30 - Training round 409/1000\n",
      "16:28:32 - Training round 410/1000\n",
      "16:28:34 - Training round 411/1000\n",
      "16:28:36 - Evaluating models\n",
      "16:28:36 - Model update bob: Average loss: 0.0174, Accuracy: 858/1598 (53.69%)\n",
      "16:28:36 - Model update bob: Average loss: 0.0174\n",
      "16:28:37 - Federated model: Average loss: 0.0174, Accuracy: 858/1598 (53.69%)\n",
      "16:28:37 - Federated model: Average loss: 0.0174\n",
      "16:28:37 - Training round 412/1000\n",
      "16:28:39 - Training round 413/1000\n",
      "16:28:41 - Training round 414/1000\n",
      "16:28:42 - Training round 415/1000\n",
      "16:28:44 - Training round 416/1000\n",
      "16:28:46 - Training round 417/1000\n",
      "16:28:48 - Training round 418/1000\n",
      "16:28:50 - Training round 419/1000\n",
      "16:28:52 - Training round 420/1000\n",
      "16:28:54 - Training round 421/1000\n",
      "16:28:56 - Evaluating models\n",
      "16:28:56 - Model update bob: Average loss: 0.0171, Accuracy: 855/1598 (53.50%)\n",
      "16:28:56 - Model update bob: Average loss: 0.0171\n",
      "16:28:57 - Federated model: Average loss: 0.0171, Accuracy: 855/1598 (53.50%)\n",
      "16:28:57 - Federated model: Average loss: 0.0171\n",
      "16:28:57 - Training round 422/1000\n",
      "16:28:59 - Training round 423/1000\n",
      "16:29:01 - Training round 424/1000\n",
      "16:29:03 - Training round 425/1000\n",
      "16:29:05 - Training round 426/1000\n",
      "16:29:06 - Training round 427/1000\n",
      "16:29:08 - Training round 428/1000\n",
      "16:29:10 - Training round 429/1000\n",
      "16:29:12 - Training round 430/1000\n",
      "16:29:14 - Training round 431/1000\n",
      "16:29:16 - Evaluating models\n",
      "16:29:17 - Model update bob: Average loss: 0.0171, Accuracy: 862/1598 (53.94%)\n",
      "16:29:17 - Model update bob: Average loss: 0.0171\n",
      "16:29:17 - Federated model: Average loss: 0.0171, Accuracy: 862/1598 (53.94%)\n",
      "16:29:17 - Federated model: Average loss: 0.0171\n",
      "16:29:17 - Training round 432/1000\n",
      "16:29:19 - Training round 433/1000\n",
      "16:29:22 - Training round 434/1000\n",
      "16:29:24 - Training round 435/1000\n",
      "16:29:27 - Training round 436/1000\n",
      "16:29:29 - Training round 437/1000\n",
      "16:29:31 - Training round 438/1000\n",
      "16:29:33 - Training round 439/1000\n",
      "16:29:35 - Training round 440/1000\n",
      "16:29:37 - Training round 441/1000\n",
      "16:29:38 - Evaluating models\n",
      "16:29:39 - Model update bob: Average loss: 0.0173, Accuracy: 863/1598 (54.01%)\n",
      "16:29:39 - Model update bob: Average loss: 0.0173\n",
      "16:29:39 - Federated model: Average loss: 0.0173, Accuracy: 863/1598 (54.01%)\n",
      "16:29:39 - Federated model: Average loss: 0.0173\n",
      "16:29:39 - Training round 442/1000\n",
      "16:29:41 - Training round 443/1000\n",
      "16:29:43 - Training round 444/1000\n",
      "16:29:45 - Training round 445/1000\n",
      "16:29:47 - Training round 446/1000\n",
      "16:29:49 - Training round 447/1000\n",
      "16:29:51 - Training round 448/1000\n",
      "16:29:53 - Training round 449/1000\n",
      "16:29:55 - Training round 450/1000\n",
      "16:29:57 - Training round 451/1000\n",
      "16:29:59 - Evaluating models\n",
      "16:29:59 - Model update bob: Average loss: 0.0173, Accuracy: 870/1598 (54.44%)\n",
      "16:29:59 - Model update bob: Average loss: 0.0173\n",
      "16:30:00 - Federated model: Average loss: 0.0173, Accuracy: 870/1598 (54.44%)\n",
      "16:30:00 - Federated model: Average loss: 0.0173\n",
      "16:30:00 - Training round 452/1000\n",
      "16:30:02 - Training round 453/1000\n",
      "16:30:04 - Training round 454/1000\n",
      "16:30:06 - Training round 455/1000\n",
      "16:30:08 - Training round 456/1000\n",
      "16:30:10 - Training round 457/1000\n",
      "16:30:11 - Training round 458/1000\n",
      "16:30:13 - Training round 459/1000\n",
      "16:30:15 - Training round 460/1000\n",
      "16:30:17 - Training round 461/1000\n",
      "16:30:19 - Evaluating models\n",
      "16:30:20 - Model update bob: Average loss: 0.0177, Accuracy: 857/1598 (53.63%)\n",
      "16:30:20 - Model update bob: Average loss: 0.0177\n",
      "16:30:20 - Federated model: Average loss: 0.0177, Accuracy: 857/1598 (53.63%)\n",
      "16:30:20 - Federated model: Average loss: 0.0177\n",
      "16:30:20 - Training round 462/1000\n",
      "16:30:22 - Training round 463/1000\n",
      "16:30:24 - Training round 464/1000\n",
      "16:30:26 - Training round 465/1000\n",
      "16:30:28 - Training round 466/1000\n",
      "16:30:30 - Training round 467/1000\n",
      "16:30:32 - Training round 468/1000\n",
      "16:30:34 - Training round 469/1000\n",
      "16:30:36 - Training round 470/1000\n",
      "16:30:38 - Training round 471/1000\n",
      "16:30:40 - Evaluating models\n",
      "16:30:40 - Model update bob: Average loss: 0.0175, Accuracy: 863/1598 (54.01%)\n",
      "16:30:40 - Model update bob: Average loss: 0.0175\n",
      "16:30:41 - Federated model: Average loss: 0.0175, Accuracy: 863/1598 (54.01%)\n",
      "16:30:41 - Federated model: Average loss: 0.0175\n",
      "16:30:41 - Training round 472/1000\n",
      "16:30:43 - Training round 473/1000\n",
      "16:30:45 - Training round 474/1000\n",
      "16:30:46 - Training round 475/1000\n",
      "16:30:48 - Training round 476/1000\n",
      "16:30:50 - Training round 477/1000\n",
      "16:30:52 - Training round 478/1000\n",
      "16:30:54 - Training round 479/1000\n",
      "16:30:56 - Training round 480/1000\n",
      "16:30:58 - Training round 481/1000\n",
      "16:31:00 - Evaluating models\n",
      "16:31:00 - Model update bob: Average loss: 0.0177, Accuracy: 857/1598 (53.63%)\n",
      "16:31:00 - Model update bob: Average loss: 0.0177\n",
      "16:31:01 - Federated model: Average loss: 0.0177, Accuracy: 857/1598 (53.63%)\n",
      "16:31:01 - Federated model: Average loss: 0.0177\n",
      "16:31:01 - Training round 482/1000\n",
      "16:31:02 - Training round 483/1000\n",
      "16:31:04 - Training round 484/1000\n",
      "16:31:06 - Training round 485/1000\n",
      "16:31:08 - Training round 486/1000\n",
      "16:31:10 - Training round 487/1000\n",
      "16:31:12 - Training round 488/1000\n",
      "16:31:14 - Training round 489/1000\n",
      "16:31:16 - Training round 490/1000\n",
      "16:31:18 - Training round 491/1000\n",
      "16:31:20 - Evaluating models\n",
      "16:31:20 - Model update bob: Average loss: 0.0176, Accuracy: 863/1598 (54.01%)\n",
      "16:31:20 - Model update bob: Average loss: 0.0176\n",
      "16:31:21 - Federated model: Average loss: 0.0176, Accuracy: 863/1598 (54.01%)\n",
      "16:31:21 - Federated model: Average loss: 0.0176\n",
      "16:31:21 - Training round 492/1000\n",
      "16:31:23 - Training round 493/1000\n",
      "16:31:25 - Training round 494/1000\n",
      "16:31:27 - Training round 495/1000\n",
      "16:31:29 - Training round 496/1000\n",
      "16:31:31 - Training round 497/1000\n",
      "16:31:33 - Training round 498/1000\n",
      "16:31:35 - Training round 499/1000\n",
      "16:31:37 - Training round 500/1000\n",
      "16:31:39 - Training round 501/1000\n",
      "16:31:41 - Evaluating models\n",
      "16:31:41 - Model update bob: Average loss: 0.0180, Accuracy: 856/1598 (53.57%)\n",
      "16:31:41 - Model update bob: Average loss: 0.0180\n",
      "16:31:41 - Federated model: Average loss: 0.0180, Accuracy: 856/1598 (53.57%)\n",
      "16:31:41 - Federated model: Average loss: 0.0180\n",
      "16:31:41 - Training round 502/1000\n",
      "16:31:43 - Training round 503/1000\n",
      "16:31:45 - Training round 504/1000\n",
      "16:31:47 - Training round 505/1000\n",
      "16:31:49 - Training round 506/1000\n",
      "16:31:51 - Training round 507/1000\n",
      "16:31:53 - Training round 508/1000\n",
      "16:31:55 - Training round 509/1000\n",
      "16:31:57 - Training round 510/1000\n",
      "16:31:59 - Training round 511/1000\n",
      "16:32:01 - Evaluating models\n",
      "16:32:01 - Model update bob: Average loss: 0.0178, Accuracy: 861/1598 (53.88%)\n",
      "16:32:01 - Model update bob: Average loss: 0.0178\n",
      "16:32:02 - Federated model: Average loss: 0.0178, Accuracy: 861/1598 (53.88%)\n",
      "16:32:02 - Federated model: Average loss: 0.0178\n",
      "16:32:02 - Training round 512/1000\n",
      "16:32:04 - Training round 513/1000\n",
      "16:32:06 - Training round 514/1000\n",
      "16:32:08 - Training round 515/1000\n",
      "16:32:10 - Training round 516/1000\n",
      "16:32:11 - Training round 517/1000\n",
      "16:32:13 - Training round 518/1000\n",
      "16:32:15 - Training round 519/1000\n",
      "16:32:17 - Training round 520/1000\n",
      "16:32:19 - Training round 521/1000\n",
      "16:32:21 - Evaluating models\n",
      "16:32:22 - Model update bob: Average loss: 0.0178, Accuracy: 862/1598 (53.94%)\n",
      "16:32:22 - Model update bob: Average loss: 0.0178\n",
      "16:32:22 - Federated model: Average loss: 0.0178, Accuracy: 862/1598 (53.94%)\n",
      "16:32:22 - Federated model: Average loss: 0.0178\n",
      "16:32:22 - Training round 522/1000\n",
      "16:32:24 - Training round 523/1000\n",
      "16:32:26 - Training round 524/1000\n",
      "16:32:28 - Training round 525/1000\n",
      "16:32:31 - Training round 526/1000\n",
      "16:32:32 - Training round 527/1000\n",
      "16:32:34 - Training round 528/1000\n",
      "16:32:36 - Training round 529/1000\n",
      "16:32:38 - Training round 530/1000\n",
      "16:32:40 - Training round 531/1000\n",
      "16:32:42 - Evaluating models\n",
      "16:32:42 - Model update bob: Average loss: 0.0179, Accuracy: 865/1598 (54.13%)\n",
      "16:32:42 - Model update bob: Average loss: 0.0179\n",
      "16:32:43 - Federated model: Average loss: 0.0179, Accuracy: 865/1598 (54.13%)\n",
      "16:32:43 - Federated model: Average loss: 0.0179\n",
      "16:32:43 - Training round 532/1000\n",
      "16:32:45 - Training round 533/1000\n",
      "16:32:47 - Training round 534/1000\n",
      "16:32:49 - Training round 535/1000\n",
      "16:32:50 - Training round 536/1000\n",
      "16:32:52 - Training round 537/1000\n",
      "16:32:54 - Training round 538/1000\n",
      "16:32:56 - Training round 539/1000\n",
      "16:32:58 - Training round 540/1000\n",
      "16:33:00 - Training round 541/1000\n",
      "16:33:02 - Evaluating models\n",
      "16:33:02 - Model update bob: Average loss: 0.0179, Accuracy: 865/1598 (54.13%)\n",
      "16:33:02 - Model update bob: Average loss: 0.0179\n",
      "16:33:03 - Federated model: Average loss: 0.0179, Accuracy: 865/1598 (54.13%)\n",
      "16:33:03 - Federated model: Average loss: 0.0179\n",
      "16:33:03 - Training round 542/1000\n",
      "16:33:05 - Training round 543/1000\n",
      "16:33:07 - Training round 544/1000\n",
      "16:33:08 - Training round 545/1000\n",
      "16:33:10 - Training round 546/1000\n",
      "16:33:12 - Training round 547/1000\n",
      "16:33:14 - Training round 548/1000\n",
      "16:33:16 - Training round 549/1000\n",
      "16:33:18 - Training round 550/1000\n",
      "16:33:20 - Training round 551/1000\n",
      "16:33:22 - Evaluating models\n",
      "16:33:22 - Model update bob: Average loss: 0.0179, Accuracy: 862/1598 (53.94%)\n",
      "16:33:22 - Model update bob: Average loss: 0.0179\n",
      "16:33:22 - Federated model: Average loss: 0.0179, Accuracy: 862/1598 (53.94%)\n",
      "16:33:22 - Federated model: Average loss: 0.0179\n",
      "16:33:22 - Training round 552/1000\n",
      "16:33:24 - Training round 553/1000\n",
      "16:33:26 - Training round 554/1000\n",
      "16:33:28 - Training round 555/1000\n",
      "16:33:30 - Training round 556/1000\n",
      "16:33:32 - Training round 557/1000\n",
      "16:33:33 - Training round 558/1000\n",
      "16:33:35 - Training round 559/1000\n",
      "16:33:37 - Training round 560/1000\n",
      "16:33:39 - Training round 561/1000\n",
      "16:33:41 - Evaluating models\n",
      "16:33:41 - Model update bob: Average loss: 0.0184, Accuracy: 856/1598 (53.57%)\n",
      "16:33:41 - Model update bob: Average loss: 0.0184\n",
      "16:33:41 - Federated model: Average loss: 0.0184, Accuracy: 856/1598 (53.57%)\n",
      "16:33:41 - Federated model: Average loss: 0.0184\n",
      "16:33:41 - Training round 562/1000\n",
      "16:33:43 - Training round 563/1000\n",
      "16:33:45 - Training round 564/1000\n",
      "16:33:47 - Training round 565/1000\n",
      "16:33:48 - Training round 566/1000\n",
      "16:33:50 - Training round 567/1000\n",
      "16:33:52 - Training round 568/1000\n",
      "16:33:54 - Training round 569/1000\n",
      "16:33:55 - Training round 570/1000\n",
      "16:33:57 - Training round 571/1000\n",
      "16:33:59 - Evaluating models\n",
      "16:34:00 - Model update bob: Average loss: 0.0189, Accuracy: 850/1598 (53.19%)\n",
      "16:34:00 - Model update bob: Average loss: 0.0189\n",
      "16:34:00 - Federated model: Average loss: 0.0189, Accuracy: 850/1598 (53.19%)\n",
      "16:34:00 - Federated model: Average loss: 0.0189\n",
      "16:34:00 - Training round 572/1000\n",
      "16:34:02 - Training round 573/1000\n",
      "16:34:04 - Training round 574/1000\n",
      "16:34:05 - Training round 575/1000\n",
      "16:34:07 - Training round 576/1000\n",
      "16:34:09 - Training round 577/1000\n",
      "16:34:11 - Training round 578/1000\n",
      "16:34:13 - Training round 579/1000\n",
      "16:34:14 - Training round 580/1000\n",
      "16:34:17 - Training round 581/1000\n",
      "16:34:19 - Evaluating models\n",
      "16:34:19 - Model update bob: Average loss: 0.0180, Accuracy: 863/1598 (54.01%)\n",
      "16:34:19 - Model update bob: Average loss: 0.0180\n",
      "16:34:20 - Federated model: Average loss: 0.0180, Accuracy: 863/1598 (54.01%)\n",
      "16:34:20 - Federated model: Average loss: 0.0180\n",
      "16:34:20 - Training round 582/1000\n",
      "16:34:22 - Training round 583/1000\n",
      "16:34:23 - Training round 584/1000\n",
      "16:34:25 - Training round 585/1000\n",
      "16:34:27 - Training round 586/1000\n",
      "16:34:29 - Training round 587/1000\n",
      "16:34:31 - Training round 588/1000\n",
      "16:34:33 - Training round 589/1000\n",
      "16:34:34 - Training round 590/1000\n",
      "16:34:36 - Training round 591/1000\n",
      "16:34:38 - Evaluating models\n",
      "16:34:39 - Model update bob: Average loss: 0.0183, Accuracy: 865/1598 (54.13%)\n",
      "16:34:39 - Model update bob: Average loss: 0.0183\n",
      "16:34:39 - Federated model: Average loss: 0.0183, Accuracy: 865/1598 (54.13%)\n",
      "16:34:39 - Federated model: Average loss: 0.0183\n",
      "16:34:39 - Training round 592/1000\n",
      "16:34:42 - Training round 593/1000\n",
      "16:34:44 - Training round 594/1000\n",
      "16:34:46 - Training round 595/1000\n",
      "16:34:48 - Training round 596/1000\n",
      "16:34:50 - Training round 597/1000\n",
      "16:34:52 - Training round 598/1000\n",
      "16:34:54 - Training round 599/1000\n",
      "16:34:56 - Training round 600/1000\n",
      "16:34:58 - Training round 601/1000\n",
      "16:35:00 - Evaluating models\n",
      "16:35:00 - Model update bob: Average loss: 0.0188, Accuracy: 852/1598 (53.32%)\n",
      "16:35:00 - Model update bob: Average loss: 0.0188\n",
      "16:35:00 - Federated model: Average loss: 0.0188, Accuracy: 852/1598 (53.32%)\n",
      "16:35:00 - Federated model: Average loss: 0.0188\n",
      "16:35:00 - Training round 602/1000\n",
      "16:35:02 - Training round 603/1000\n",
      "16:35:04 - Training round 604/1000\n",
      "16:35:06 - Training round 605/1000\n",
      "16:35:08 - Training round 606/1000\n",
      "16:35:10 - Training round 607/1000\n",
      "16:35:12 - Training round 608/1000\n",
      "16:35:14 - Training round 609/1000\n",
      "16:35:16 - Training round 610/1000\n",
      "16:35:18 - Training round 611/1000\n",
      "16:35:20 - Evaluating models\n",
      "16:35:20 - Model update bob: Average loss: 0.0187, Accuracy: 859/1598 (53.75%)\n",
      "16:35:20 - Model update bob: Average loss: 0.0187\n",
      "16:35:21 - Federated model: Average loss: 0.0187, Accuracy: 859/1598 (53.75%)\n",
      "16:35:21 - Federated model: Average loss: 0.0187\n",
      "16:35:21 - Training round 612/1000\n",
      "16:35:23 - Training round 613/1000\n",
      "16:35:25 - Training round 614/1000\n",
      "16:35:27 - Training round 615/1000\n",
      "16:35:29 - Training round 616/1000\n",
      "16:35:31 - Training round 617/1000\n",
      "16:35:32 - Training round 618/1000\n",
      "16:35:34 - Training round 619/1000\n",
      "16:35:36 - Training round 620/1000\n",
      "16:35:38 - Training round 621/1000\n",
      "16:35:40 - Evaluating models\n",
      "16:35:41 - Model update bob: Average loss: 0.0187, Accuracy: 863/1598 (54.01%)\n",
      "16:35:41 - Model update bob: Average loss: 0.0187\n",
      "16:35:41 - Federated model: Average loss: 0.0187, Accuracy: 863/1598 (54.01%)\n",
      "16:35:41 - Federated model: Average loss: 0.0187\n",
      "16:35:41 - Training round 622/1000\n",
      "16:35:43 - Training round 623/1000\n",
      "16:35:45 - Training round 624/1000\n",
      "16:35:47 - Training round 625/1000\n",
      "16:35:48 - Training round 626/1000\n",
      "16:35:50 - Training round 627/1000\n",
      "16:35:52 - Training round 628/1000\n",
      "16:35:55 - Training round 629/1000\n",
      "16:35:57 - Training round 630/1000\n",
      "16:35:59 - Training round 631/1000\n",
      "16:36:01 - Evaluating models\n",
      "16:36:01 - Model update bob: Average loss: 0.0189, Accuracy: 863/1598 (54.01%)\n",
      "16:36:01 - Model update bob: Average loss: 0.0189\n",
      "16:36:01 - Federated model: Average loss: 0.0189, Accuracy: 863/1598 (54.01%)\n",
      "16:36:01 - Federated model: Average loss: 0.0189\n",
      "16:36:01 - Training round 632/1000\n",
      "16:36:03 - Training round 633/1000\n",
      "16:36:05 - Training round 634/1000\n",
      "16:36:07 - Training round 635/1000\n",
      "16:36:09 - Training round 636/1000\n",
      "16:36:11 - Training round 637/1000\n",
      "16:36:13 - Training round 638/1000\n",
      "16:36:15 - Training round 639/1000\n",
      "16:36:17 - Training round 640/1000\n",
      "16:36:19 - Training round 641/1000\n",
      "16:36:20 - Evaluating models\n",
      "16:36:21 - Model update bob: Average loss: 0.0196, Accuracy: 851/1598 (53.25%)\n",
      "16:36:21 - Model update bob: Average loss: 0.0196\n",
      "16:36:21 - Federated model: Average loss: 0.0196, Accuracy: 851/1598 (53.25%)\n",
      "16:36:21 - Federated model: Average loss: 0.0196\n",
      "16:36:21 - Training round 642/1000\n",
      "16:36:23 - Training round 643/1000\n",
      "16:36:25 - Training round 644/1000\n",
      "16:36:27 - Training round 645/1000\n",
      "16:36:29 - Training round 646/1000\n",
      "16:36:31 - Training round 647/1000\n",
      "16:36:33 - Training round 648/1000\n",
      "16:36:35 - Training round 649/1000\n",
      "16:36:37 - Training round 650/1000\n",
      "16:36:39 - Training round 651/1000\n",
      "16:36:41 - Evaluating models\n",
      "16:36:42 - Model update bob: Average loss: 0.0189, Accuracy: 852/1598 (53.32%)\n",
      "16:36:42 - Model update bob: Average loss: 0.0189\n",
      "16:36:42 - Federated model: Average loss: 0.0189, Accuracy: 852/1598 (53.32%)\n",
      "16:36:42 - Federated model: Average loss: 0.0189\n",
      "16:36:42 - Training round 652/1000\n",
      "16:36:44 - Training round 653/1000\n",
      "16:36:47 - Training round 654/1000\n",
      "16:36:49 - Training round 655/1000\n",
      "16:36:51 - Training round 656/1000\n",
      "16:36:54 - Training round 657/1000\n",
      "16:36:56 - Training round 658/1000\n",
      "16:36:58 - Training round 659/1000\n",
      "16:37:00 - Training round 660/1000\n",
      "16:37:01 - Training round 661/1000\n",
      "16:37:03 - Evaluating models\n",
      "16:37:04 - Model update bob: Average loss: 0.0195, Accuracy: 850/1598 (53.19%)\n",
      "16:37:04 - Model update bob: Average loss: 0.0195\n",
      "16:37:04 - Federated model: Average loss: 0.0195, Accuracy: 850/1598 (53.19%)\n",
      "16:37:04 - Federated model: Average loss: 0.0195\n",
      "16:37:04 - Training round 662/1000\n",
      "16:37:06 - Training round 663/1000\n",
      "16:37:08 - Training round 664/1000\n",
      "16:37:10 - Training round 665/1000\n",
      "16:37:12 - Training round 666/1000\n",
      "16:37:14 - Training round 667/1000\n",
      "16:37:16 - Training round 668/1000\n",
      "16:37:18 - Training round 669/1000\n",
      "16:37:20 - Training round 670/1000\n",
      "16:37:22 - Training round 671/1000\n",
      "16:37:24 - Evaluating models\n",
      "16:37:24 - Model update bob: Average loss: 0.0194, Accuracy: 853/1598 (53.38%)\n",
      "16:37:24 - Model update bob: Average loss: 0.0194\n",
      "16:37:25 - Federated model: Average loss: 0.0194, Accuracy: 853/1598 (53.38%)\n",
      "16:37:25 - Federated model: Average loss: 0.0194\n",
      "16:37:25 - Training round 672/1000\n",
      "16:37:27 - Training round 673/1000\n",
      "16:37:29 - Training round 674/1000\n",
      "16:37:31 - Training round 675/1000\n",
      "16:37:32 - Training round 676/1000\n",
      "16:37:34 - Training round 677/1000\n",
      "16:37:36 - Training round 678/1000\n",
      "16:37:38 - Training round 679/1000\n",
      "16:37:40 - Training round 680/1000\n",
      "16:37:42 - Training round 681/1000\n",
      "16:37:44 - Evaluating models\n",
      "16:37:44 - Model update bob: Average loss: 0.0192, Accuracy: 858/1598 (53.69%)\n",
      "16:37:44 - Model update bob: Average loss: 0.0192\n",
      "16:37:44 - Federated model: Average loss: 0.0192, Accuracy: 858/1598 (53.69%)\n",
      "16:37:44 - Federated model: Average loss: 0.0192\n",
      "16:37:44 - Training round 682/1000\n",
      "16:37:46 - Training round 683/1000\n",
      "16:37:48 - Training round 684/1000\n",
      "16:37:50 - Training round 685/1000\n",
      "16:37:52 - Training round 686/1000\n",
      "16:37:54 - Training round 687/1000\n",
      "16:37:56 - Training round 688/1000\n",
      "16:37:58 - Training round 689/1000\n",
      "16:38:00 - Training round 690/1000\n",
      "16:38:02 - Training round 691/1000\n",
      "16:38:04 - Evaluating models\n"
     ]
    },
    {
     "ename": "WebSocketConnectionClosedException",
     "evalue": "Connection is already closed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebSocketConnectionClosedException\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5daa927b33de>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m             )\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;31m# Federate models (note that this will also change the model in models[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mworker_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_loss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mworker_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/android_virus_GPU/GPU_virus/virus_test_GPU/run_websocket_client.py\u001b[0m in \u001b[0;36mevaluate_model_on_worker\u001b[0;34m(model_identifier, worker, dataset_key, model, nr_bins, batch_size, device, print_target_hist)\u001b[0m\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mtrain_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     result = worker.evaluate(\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/syft/federated/train_config.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \"\"\"\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# Send traced model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_and_send_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# Send loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/syft/federated/train_config.py\u001b[0m in \u001b[0;36m_wrap_and_send_obj\u001b[0;34m(self, obj, location)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;34m\"\"\"Wrappers object and send it to location.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mobj_with_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID_PROVIDER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mobj_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_with_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mobj_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_ptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_at_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj_ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj, workers, ptr_id, garbage_collect_data, create_pointer, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;31m# Send the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;31m# If we don't need to create the pointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_obj\u001b[0;34m(self, obj, location)\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0mreceive\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mObjectMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     def request_obj(\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mbin_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;31m# Step 3: deserialize the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_pending_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/syft/workers/websocket_client.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;34m\"\"\"Forwards a message to the WebsocketServerWorker\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_to_websocket_server_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Websocket connection closed (worker: %s)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/syft/workers/websocket_client.py\u001b[0m in \u001b[0;36m_forward_to_websocket_server_worker\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_to_websocket_server_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinascii\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexlify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinascii\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munhexlify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/websocket/_core.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \"\"\"\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mopcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mopcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mABNF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPCODE_TEXT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/websocket/_core.py\u001b[0m in \u001b[0;36mrecv_data\u001b[0;34m(self, control_frame)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mreturn\u001b[0m  \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \"\"\"\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mopcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_data_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mopcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/websocket/_core.py\u001b[0m in \u001b[0;36mrecv_data_frame\u001b[0;34m(self, control_frame)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \"\"\"\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;31m# handle error:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/websocket/_core.py\u001b[0m in \u001b[0;36mrecv_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mABNF\u001b[0m \u001b[0mframe\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \"\"\"\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTATUS_NORMAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/websocket/_abnf.py\u001b[0m in \u001b[0;36mrecv_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_received_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsv3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/websocket/_abnf.py\u001b[0m in \u001b[0;36mrecv_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/websocket/_abnf.py\u001b[0m in \u001b[0;36mrecv_strict\u001b[0;34m(self, bufsize)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;31m# buffers allocated and then shrunk, which results in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# fragmentation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0mbytes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mshortage\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/websocket/_core.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, bufsize)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mWebSocketConnectionClosedException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.7/site-packages/websocket/_socket.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(sock, bufsize)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbytes_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         raise WebSocketConnectionClosedException(\n\u001b[0;32m--> 115\u001b[0;31m             \"Connection is already closed.\")\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbytes_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebSocketConnectionClosedException\u001b[0m: Connection is already closed."
     ]
    }
   ],
   "source": [
    "\n",
    "args = rwc.define_and_get_arguments(args=[])\n",
    "learning_rate = args.lr\n",
    "\n",
    "device = \"cuda\"  #torch.device(\"cpu\")\n",
    "traced_model = torch.jit.trace(model, torch.zeros([1,1,22,22], dtype=torch.float).to(device),check_trace=False)\n",
    "for curr_round in range(1, args.training_rounds + 1):\n",
    "    logger.info(\"Training round %s/%s\", curr_round, args.training_rounds)\n",
    "\n",
    "    results = await asyncio.gather(\n",
    "        *[\n",
    "            rwc.fit_model_on_worker(\n",
    "                worker=worker,\n",
    "                traced_model=traced_model,\n",
    "                batch_size=args.batch_size,\n",
    "                curr_round=curr_round,\n",
    "                max_nr_batches=args.federate_after_n_batches,\n",
    "                lr=learning_rate,\n",
    "            )\n",
    "            for worker in worker_instances\n",
    "        ]\n",
    "    )\n",
    "    models = {}\n",
    "    loss_values = {}\n",
    "\n",
    "    test_models = curr_round % 10 == 1 or curr_round == args.training_rounds\n",
    "    if test_models:\n",
    "        logger.info(\"Evaluating models\")\n",
    "        np.set_printoptions(formatter={\"float\": \"{: .0f}\".format})\n",
    "        for worker_id, worker_model, _ in results:\n",
    "            rwc.evaluate_model_on_worker(\n",
    "                model_identifier=\"Model update \" + worker_id,\n",
    "                worker=testing,\n",
    "                dataset_key=\"mnist_testing\",\n",
    "                model=worker_model,\n",
    "                nr_bins=5,\n",
    "                batch_size=128,\n",
    "                print_target_hist=False,\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "    # Federate models (note that this will also change the model in models[0]\n",
    "    for worker_id, worker_model, worker_loss in results:\n",
    "        if worker_model is not None:\n",
    "            models[worker_id] = worker_model\n",
    "            loss_values[worker_id] = worker_loss\n",
    "\n",
    "    traced_model = utils.federated_avg(models)\n",
    "\n",
    "    if test_models:\n",
    "        rwc.evaluate_model_on_worker(\n",
    "            model_identifier=\"Federated model\",\n",
    "            worker=testing,\n",
    "            dataset_key=\"mnist_testing\",\n",
    "            model=traced_model,\n",
    "            nr_bins=5,\n",
    "            batch_size=128,\n",
    "            print_target_hist=False,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "    # decay learning rate\n",
    "    learning_rate = max(0.98 * learning_rate, args.lr * 0.01)\n",
    "\n",
    "if args.save_model:\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "asyncio.get_event_loop().run_until_complete(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 40 rounds of training we achieve an accuracy larger than 95% on the entire testing dataset. \n",
    "This is impressing, given that no worker has access to more than 4 digits!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "### Star PySyft on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the GitHub repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft GitHub Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for GitHub issues marked \"good first issue\".\n",
    "\n",
    "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
